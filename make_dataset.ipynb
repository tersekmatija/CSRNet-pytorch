{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import scipy.io as io\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter \n",
    "import scipy\n",
    "from scipy import spatial\n",
    "import json\n",
    "from matplotlib import cm as CM\n",
    "from image import *\n",
    "from model import CSRNet\n",
    "import torch\n",
    "import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is borrowed from https://github.com/davideverona/deep-crowd-counting_crowdnet\n",
    "def gaussian_filter_density(gt):\n",
    "    #Generates a density map using Gaussian filter transformation\n",
    "    \n",
    "    density = np.zeros(gt.shape, dtype=np.float32)\n",
    "    \n",
    "    gt_count = np.count_nonzero(gt)\n",
    "    \n",
    "    if gt_count == 0:\n",
    "        return density\n",
    "\n",
    "    # FInd out the K nearest neighbours using a KDTree\n",
    "    \n",
    "    pts = np.array(list(zip(np.nonzero(gt)[1].ravel(), np.nonzero(gt)[0].ravel())))\n",
    "    leafsize = 2048\n",
    "    \n",
    "    # build kdtree\n",
    "    tree = scipy.spatial.KDTree(pts.copy(), leafsize=leafsize)\n",
    "    \n",
    "    # query kdtree\n",
    "    distances, locations = tree.query(pts, k=4)\n",
    "\n",
    "        \n",
    "    for i, pt in enumerate(pts):\n",
    "        pt2d = np.zeros(gt.shape, dtype=np.float32)\n",
    "        pt2d[pt[1],pt[0]] = 1.\n",
    "        if gt_count > 1:\n",
    "            sigma = (distances[i][1]+distances[i][2]+distances[i][3])*0.1\n",
    "        else:\n",
    "            sigma = np.average(np.array(gt.shape))/2./2. #case: 1 point\n",
    "        \n",
    "        #Convolve with the gaussian filter\n",
    "        \n",
    "        density += scipy.ndimage.filters.gaussian_filter(pt2d, sigma, mode='constant')\n",
    "    \n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the root to the Shanghai dataset you download\n",
    "root = '.\\\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now generate the ShanghaiA's ground truth\n",
    "part_A_train = os.path.join(root,'ShanghaiA\\\\train_data','images')\n",
    "part_A_test = os.path.join(root,'ShanghaiA\\\\test_data','images')\n",
    "part_B_train = os.path.join(root,'ShanghaiB\\\\train_data','images')\n",
    "part_B_test = os.path.join(root,'ShanghaiB\\\\test_data','images')\n",
    "path_sets = [part_A_train,part_A_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "482\n"
    }
   ],
   "source": [
    "# List of all image paths\n",
    "\n",
    "img_paths = []\n",
    "for path in path_sets:\n",
    "    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n",
    "        img_paths.append(img_path)\n",
    "print(len(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "2%|‚ñè         | 8/482 [05:21<5:17:49, 40.23s/it]\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-19a3c6848f52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# generate density map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgaussian_filter_density\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# File path to save density map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-05e83d535815>\u001b[0m in \u001b[0;36mgaussian_filter_density\u001b[1;34m(gt)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m#Convolve with the gaussian filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mdensity\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'constant'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdensity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\csrnet-pytorch\\lib\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mgaussian_filter\u001b[1;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             gaussian_filter1d(input, sigma, axis, order, output,\n\u001b[1;32m--> 299\u001b[1;33m                               mode, cval, truncate)\n\u001b[0m\u001b[0;32m    300\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\csrnet-pytorch\\lib\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mgaussian_filter1d\u001b[1;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;31m# Since we are calling correlate, not convolve, revert the kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_gaussian_kernel1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcorrelate1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\csrnet-pytorch\\lib\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mcorrelate1d\u001b[1;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     _nd_image.correlate1d(input, weights, axis, output, mode, cval,\n\u001b[1;32m---> 95\u001b[1;33m                           origin)\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "i = 0\n",
    "for img_path in tqdm(img_paths):\n",
    "        \n",
    "    \n",
    "    # Load sparse matrix\n",
    "    mat = io.loadmat(img_path.replace('.jpg','.mat').replace('images','ground_truth').replace('IMG_','GT_IMG_'))\n",
    "    \n",
    "    #Read image\n",
    "    img= plt.imread(img_path)\n",
    "    \n",
    "    # Create a zero matrix of image size\n",
    "    k = np.zeros((img.shape[0],img.shape[1]))\n",
    "    \n",
    "    gt = mat[\"image_info\"][0,0][0,0][0]\n",
    "    \n",
    "    #Generate hot encoded matrix of sparse matrix\n",
    "    for i in range(0,len(gt)):\n",
    "        if int(gt[i][1])<img.shape[0] and int(gt[i][0])<img.shape[1]:\n",
    "            k[int(gt[i][1]),int(gt[i][0])]=1\n",
    "    \n",
    "    # generate density map\n",
    "    k = gaussian_filter_density(k)\n",
    "    \n",
    "    # File path to save density map\n",
    "    file_path = img_path.replace('.jpg','.h5').replace('images','ground_truth')\n",
    "    \n",
    "    \n",
    "    with h5py.File(file_path, 'w') as hf:\n",
    "            hf['density'] = k\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now see a sample from ShanghaiA\n",
    "plt.imshow(Image.open(img_paths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_file = h5py.File(img_paths[0].replace('.jpg','.h5').replace('images','ground_truth'),'r')\n",
    "groundtruth = np.asarray(gt_file['density'])\n",
    "plt.imshow(groundtruth,cmap=CM.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(groundtruth)# don't mind this slight variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now generate the ShanghaiB's ground truth\n",
    "path_sets = [part_B_train,part_B_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = []\n",
    "for path in path_sets:\n",
    "    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n",
    "        img_paths.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "i = 0\n",
    "for img_path in tqdm(img_paths):\n",
    "        \n",
    "    \n",
    "    # Load sparse matrix\n",
    "    mat = io.loadmat(img_path.replace('.jpg','.mat').replace('images','ground_truth').replace('IMG_','GT_IMG_'))\n",
    "    \n",
    "    #Read image\n",
    "    img= plt.imread(img_path)\n",
    "    \n",
    "    # Create a zero matrix of image size\n",
    "    k = np.zeros((img.shape[0],img.shape[1]))\n",
    "    \n",
    "    gt = mat[\"image_info\"][0,0][0,0][0]\n",
    "    \n",
    "    #Generate hot encoded matrix of sparse matrix\n",
    "    for i in range(0,len(gt)):\n",
    "        if int(gt[i][1])<img.shape[0] and int(gt[i][0])<img.shape[1]:\n",
    "            k[int(gt[i][1]),int(gt[i][0])]=1\n",
    "    \n",
    "    # generate density map\n",
    "    k = gaussian_filter_density(k)\n",
    "    \n",
    "    # File path to save density map\n",
    "    file_path = img_path.replace('.jpg','.h5').replace('images','ground_truth')\n",
    "    \n",
    "    \n",
    "    with h5py.File(file_path, 'w') as hf:\n",
    "            hf['density'] = k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('csrnet-pytorch': conda)",
   "language": "python",
   "name": "python361264bitcsrnetpytorchcondab380a81b3fed4ebbb1b0092d416f8b9d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}